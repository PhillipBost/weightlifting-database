name: USAW Daily WSO & Club Directory Pipeline

on:
  schedule:
    # Run daily at 9 PM UTC (4 PM EST)
    - cron: '0 21 * * *'
  workflow_dispatch: # Allow manual triggering
    inputs:
      skip_meets:
        description: 'Skip meet address scraping'
        required: false
        type: boolean
        default: false
      skip_clubs:
        description: 'Skip club scraping'
        required: false
        type: boolean
        default: false

jobs:
  scrape-meet-addresses:
    if: ${{ !inputs.skip_meets }}
    runs-on: ubuntu-latest
    timeout-minutes: 360 # 6 hours for scraping and geocoding all low-precision meets

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Calculate date range (last month + current month)
        id: dates
        run: |
          # Get current date components (remove leading zeros to avoid octal interpretation)
          current_year=$(date +%Y)
          current_month=$(date +%-m)  # %-m removes leading zeros

          # Calculate last month
          if [ $current_month -eq 1 ]; then
            last_month=12
            last_year=$((current_year - 1))
          else
            last_month=$((current_month - 1))
            last_year=$current_year
          fi

          # Format months with leading zeros
          last_month_padded=$(printf "%02d" $last_month)
          current_month_padded=$(printf "%02d" $current_month)

          # Calculate date range
          from_date="${last_year}-${last_month_padded}-01"

          # Get last day of current month
          if [ $current_month -eq 12 ]; then
            next_month=1
            next_year=$((current_year + 1))
          else
            next_month=$((current_month + 1))
            next_year=$current_year
          fi

          # Get last day of current month by getting first day of next month and subtracting 1 day
          to_date=$(date -d "${next_year}-$(printf "%02d" $next_month)-01 -1 day" +%Y-%m-%d)

          echo "from_date=$from_date" >> $GITHUB_OUTPUT
          echo "to_date=$to_date" >> $GITHUB_OUTPUT
          echo "ðŸ“… Date range: $from_date to $to_date"

      - name: Create output and logs directories
        run: |
          mkdir -p output logs

      - name: Scrape meet addresses
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
        run: |
          echo "ðŸ‹ï¸ Starting meet address scraping..."
          echo "Date range: ${{ steps.dates.outputs.from_date }} to ${{ steps.dates.outputs.to_date }}"

          node scripts/production/meet-address-scraper.js \
            --from-date "${{ steps.dates.outputs.from_date }}" \
            --to-date "${{ steps.dates.outputs.to_date }}"

      - name: Geocode and import addresses
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
        run: |
          echo "ðŸŒ Starting geocoding and import..."
          echo "ðŸ“ Geocoding meets with precision score â‰¤3 or NULL..."

          node scripts/geographic/geocode-and-import.js

      - name: Upload meet results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: meet-addresses-${{ steps.dates.outputs.from_date }}-to-${{ steps.dates.outputs.to_date }}
          path: |
            logs/meet-address-scraper.log
            logs/geocode-import.log
          retention-days: 30

  scrape-clubs:
    if: ${{ !inputs.skip_clubs }}
    runs-on: ubuntu-latest
    timeout-minutes: 45 # Increased timeout for enhanced scraping with retries

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Create directories
        run: |
          mkdir -p output logs

      - name: Run club scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
        run: |
          set -o pipefail
          echo "ðŸ‹ï¸ Starting club scraping..."
          echo "ðŸ• Start time: $(date +'%Y-%m-%d %H:%M:%S %Z')"

          node scripts/production/club-scraper.js 2>&1 | tee logs/club-scraper.log

          # Check if the script ran successfully
          if [ $? -eq 0 ]; then
            echo "âœ… Club scraping completed successfully"
          else
            echo "âŒ Club scraping failed"
            exit 1
          fi

      - name: Upload club results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: club-scraper-results-${{ github.run_number }}
          path: |
            output/clubs.json
            logs/club-scraper.log
          retention-days: 30

  create-summary:
    needs: [scrape-meet-addresses, scrape-clubs]
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Create comprehensive summary
        run: |
          echo "## ðŸ“Š Daily Data Collection Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Meet addresses summary
          if [ "${{ inputs.skip_meets }}" == "true" ]; then
            echo "### ðŸ“ Meet Addresses: Skipped" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.scrape-meet-addresses.result }}" == "success" ]; then
            echo "### ðŸ“ Meet Addresses: âœ… Success" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** Successfully scraped addresses and geocoded meets" >> $GITHUB_STEP_SUMMARY
            echo "- **Actions:** Scraped directory â†’ Updated database â†’ Geocoded coordinates" >> $GITHUB_STEP_SUMMARY
          else
            echo "### ðŸ“ Meet Addresses: âŒ Failed" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** See workflow logs for details" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY

          # Club scraping summary
          if [ "${{ inputs.skip_clubs }}" == "true" ]; then
            echo "### ðŸ‹ï¸ Club Scraping: Skipped" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.scrape-clubs.result }}" == "success" ]; then
            echo "### ðŸ‹ï¸ Club Scraping: âœ… Success" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** Successfully scraped club directory" >> $GITHUB_STEP_SUMMARY
            echo "- **Actions:** Scraped clubs â†’ Updated database â†’ Geocoded new entries" >> $GITHUB_STEP_SUMMARY
          else
            echo "### ðŸ‹ï¸ Club Scraping: âŒ Failed" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** See workflow logs for details" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ”„ Pipeline Integration" >> $GITHUB_STEP_SUMMARY
          echo "- **Next Steps:** Daily Data Processing pipeline (WSO assignment + Analytics)" >> $GITHUB_STEP_SUMMARY
          echo "- **Schedule:** Data processing runs at 3:30 AM UTC (6.5 hours after this starts)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Data collection artifacts available in workflow artifacts**" >> $GITHUB_STEP_SUMMARY

      - name: Cleanup output files
        if: always()
        run: |
          # Keep logs but clean up large output files to save space
          rm -f output/meet_addresses.json output/clubs.json