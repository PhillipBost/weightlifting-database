name: Daily Weightlifting Meet Scraper

on:
  schedule:
    # 2 AM EST = 7 AM UTC (Standard Time) / 6 AM UTC (Daylight Time)
    # Using 7 AM UTC to be safe during EST
    - cron: '0 7 * * *'
  workflow_dispatch:

jobs:
  scrape-and-import:
    runs-on: ubuntu-latest
    
    # Set timezone for the entire job
    env:
      TZ: America/New_York

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Set timezone and show current time
        run: |
          # Set system timezone to EST
          sudo timedatectl set-timezone America/New_York
          echo "ğŸ• Workflow started at: $(date)"
          echo "ğŸ“… Date: $(date +'%Y-%m-%d %H:%M:%S %Z')"    
          
      - name: Install dependencies
        run: npm install
        
      - name: Run daily scraper and database import
        run: |
          echo "ğŸš€ Starting scraper at: $(date +'%Y-%m-%d %H:%M:%S %Z')"
          npm start
          echo "âœ… Scraper completed at: $(date +'%Y-%m-%d %H:%M:%S %Z')"
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
          TZ: America/New_York
      
      - name: Create output directory structure
        run: |
          mkdir -p output/athletes
          mkdir -p logs
          echo "ğŸ“ Created output directory structure"
      
      - name: Fetch elevation data for new meet locations
        run: |
          echo "ğŸ—» Starting elevation fetch at: $(date +'%Y-%m-%d %H:%M:%S %Z')"
          node scripts/geographic/elevation-fetcher.js
          echo "âœ… Elevation fetch completed at: $(date +'%Y-%m-%d %H:%M:%S %Z')"
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
          TZ: America/New_York
      
      - name: Upload CSV artifact (for debugging)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraped-csv-${{ github.run_number }}
          path: |
              meets_*.csv
              completed_divisions.csv
              athlete_extraction_details.csv
              output/athletes/*.csv
          retention-days: 7
      
      - name: Show completion summary
        if: always()
        run: |
          echo "ğŸ Workflow completed at: $(date +'%Y-%m-%d %H:%M:%S %Z')"
          echo "ğŸ“Š Summary complete"    

      - name: Notify on failure
        if: failure()
        run: |
          echo "ğŸš¨ Daily scraper failed at: $(date +'%Y-%m-%d %H:%M:%S %Z')"
          echo "Check the logs above for details."