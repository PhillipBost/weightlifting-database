name: Weekly Data Collection Pipeline

on:
  schedule:
    # Run every Sunday at 6 AM UTC
    - cron: '0 6 * * 0'
  workflow_dispatch: # Allow manual triggering
    inputs:
      skip_meets:
        description: 'Skip meet address scraping'
        required: false
        type: boolean
        default: false
      skip_clubs:
        description: 'Skip club scraping'
        required: false
        type: boolean
        default: false

jobs:
  scrape-meet-addresses:
    if: ${{ !inputs.skip_meets }}
    runs-on: ubuntu-latest
    timeout-minutes: 45 # Generous timeout for scraping and geocoding

    outputs:
      has_addresses: ${{ steps.check_addresses.outputs.has_addresses }}
      meet_count: ${{ steps.check_addresses.outputs.meet_count }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Calculate date range (last month + current month)
        id: dates
        run: |
          # Get current date components (remove leading zeros to avoid octal interpretation)
          current_year=$(date +%Y)
          current_month=$(date +%-m)  # %-m removes leading zeros

          # Calculate last month
          if [ $current_month -eq 1 ]; then
            last_month=12
            last_year=$((current_year - 1))
          else
            last_month=$((current_month - 1))
            last_year=$current_year
          fi

          # Format months with leading zeros
          last_month_padded=$(printf "%02d" $last_month)
          current_month_padded=$(printf "%02d" $current_month)

          # Calculate date range
          from_date="${last_year}-${last_month_padded}-01"

          # Get last day of current month
          if [ $current_month -eq 12 ]; then
            next_month=1
            next_year=$((current_year + 1))
          else
            next_month=$((current_month + 1))
            next_year=$current_year
          fi

          # Get last day of current month by getting first day of next month and subtracting 1 day
          to_date=$(date -d "${next_year}-$(printf "%02d" $next_month)-01 -1 day" +%Y-%m-%d)

          echo "from_date=$from_date" >> $GITHUB_OUTPUT
          echo "to_date=$to_date" >> $GITHUB_OUTPUT
          echo "📅 Date range: $from_date to $to_date"

      - name: Create output and logs directories
        run: |
          mkdir -p output logs

      - name: Scrape meet addresses
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
        run: |
          echo "🏋️ Starting meet address scraping..."
          echo "Date range: ${{ steps.dates.outputs.from_date }} to ${{ steps.dates.outputs.to_date }}"

          node scripts/production/meet-address-scraper.js \
            --from-date "${{ steps.dates.outputs.from_date }}" \
            --to-date "${{ steps.dates.outputs.to_date }}"

      - name: Check if addresses were scraped
        id: check_addresses
        run: |
          if [ -f "output/meet_addresses.json" ]; then
            # Count meets in the output file
            meet_count=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('output/meet_addresses.json', 'utf8'));
                console.log(data.meets ? data.meets.length : 0);
              } catch (e) {
                console.log(0);
              }
            ")
            echo "meet_count=$meet_count" >> $GITHUB_OUTPUT
            echo "📊 Found $meet_count meets with addresses"

            if [ $meet_count -gt 0 ]; then
              echo "has_addresses=true" >> $GITHUB_OUTPUT
            else
              echo "has_addresses=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "❌ No meet_addresses.json file found"
            echo "has_addresses=false" >> $GITHUB_OUTPUT
            echo "meet_count=0" >> $GITHUB_OUTPUT
          fi

      - name: Geocode and import addresses
        if: steps.check_addresses.outputs.has_addresses == 'true'
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
        run: |
          echo "🌍 Starting geocoding and import..."
          echo "Processing ${{ steps.check_addresses.outputs.meet_count }} meets"

          node scripts/geographic/geocode-and-import.js

      - name: Upload meet results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: meet-addresses-${{ steps.dates.outputs.from_date }}-to-${{ steps.dates.outputs.to_date }}
          path: |
            output/meet_addresses.json
            logs/meet-address-scraper.log
            logs/geocode-import.log
          retention-days: 30

  scrape-clubs:
    if: ${{ !inputs.skip_clubs }}
    runs-on: ubuntu-latest
    timeout-minutes: 45 # Increased timeout for enhanced scraping with retries

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Create directories
        run: |
          mkdir -p output logs

      - name: Run club scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SECRET_KEY: ${{ secrets.SUPABASE_SECRET_KEY }}
        run: |
          set -o pipefail
          echo "🏋️ Starting club scraping..."
          echo "🕐 Start time: $(date +'%Y-%m-%d %H:%M:%S %Z')"

          node scripts/production/club-scraper.js 2>&1 | tee logs/club-scraper.log

          # Check if the script ran successfully
          if [ $? -eq 0 ]; then
            echo "✅ Club scraping completed successfully"
          else
            echo "❌ Club scraping failed"
            exit 1
          fi

      - name: Upload club results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: club-scraper-results-${{ github.run_number }}
          path: |
            output/clubs.json
            logs/club-scraper.log
          retention-days: 30

  create-summary:
    needs: [scrape-meet-addresses, scrape-clubs]
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Create comprehensive summary
        run: |
          echo "## 📊 Weekly Data Collection Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Meet addresses summary
          if [ "${{ inputs.skip_meets }}" == "true" ]; then
            echo "### 📍 Meet Addresses: Skipped" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.scrape-meet-addresses.result }}" == "success" ]; then
            echo "### 📍 Meet Addresses: ✅ Success" >> $GITHUB_STEP_SUMMARY
            echo "- **Meets Found:** ${{ needs.scrape-meet-addresses.outputs.meet_count }}" >> $GITHUB_STEP_SUMMARY

            if [ "${{ needs.scrape-meet-addresses.outputs.has_addresses }}" == "true" ]; then
              echo "- **Status:** Successfully scraped and geocoded meet addresses" >> $GITHUB_STEP_SUMMARY
              echo "- **Actions:** Scraped directory → Geocoded → Imported to database" >> $GITHUB_STEP_SUMMARY
            else
              echo "- **Status:** No new meets found for date range" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "### 📍 Meet Addresses: ❌ Failed" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** See workflow logs for details" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY

          # Club scraping summary
          if [ "${{ inputs.skip_clubs }}" == "true" ]; then
            echo "### 🏋️ Club Scraping: Skipped" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.scrape-clubs.result }}" == "success" ]; then
            echo "### 🏋️ Club Scraping: ✅ Success" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** Successfully scraped club directory" >> $GITHUB_STEP_SUMMARY
            echo "- **Actions:** Scraped clubs → Updated database → Geocoded new entries" >> $GITHUB_STEP_SUMMARY
          else
            echo "### 🏋️ Club Scraping: ❌ Failed" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** See workflow logs for details" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔄 Pipeline Integration" >> $GITHUB_STEP_SUMMARY
          echo "- **Next Steps:** Weekly Data Processing pipeline (WSO assignment + Analytics)" >> $GITHUB_STEP_SUMMARY
          echo "- **Schedule:** Data processing runs 30 minutes after this completes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Data collection artifacts available in workflow artifacts**" >> $GITHUB_STEP_SUMMARY

      - name: Cleanup output files
        if: always()
        run: |
          # Keep logs but clean up large output files to save space
          rm -f output/meet_addresses.json output/clubs.json